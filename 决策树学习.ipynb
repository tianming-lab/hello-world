{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树的构造  \n",
    "决策树的一般流程  \n",
    "(1) 收集数据:可以使用任何方法。  \n",
    "(2) 准备数据:树构造算法只适用于标称型数据,因此数值型数据必须离散化。  \n",
    "(3) 分析数据:可以使用任何方法,构造树完成之后,我们应该检查图形是否符合预期。  \n",
    "(4) 训练算法:构造树的数据结构。  \n",
    "(5) 测试算法:使用经验树计算错误率。  \n",
    "(6) 使用算法:此步骤可以适用于任何监督学习算法,而使用决策树可以更好地理解数据的内在含义。  \n",
    "创建分支的伪代码函数 createBranch() 如下所示:  \n",
    "检测数据集中的每个子项是否属于同一分类:  \n",
    "&emsp;If so return 类标签;  \n",
    "&emsp;Else  \n",
    "&emsp;&emsp;寻找划分数据集的最好特征  \n",
    "&emsp;&emsp;划分数据集  \n",
    "&emsp;&emsp;创建分支节点  \n",
    "&emsp;&emsp;for 每个划分的子集  \n",
    "&emsp;&emsp;&emsp;调用函数 createBranch 并增加返回结果到分支节点中  \n",
    "&emsp;&emsp;return 分支节点\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 信息增益  \n",
    "&emsp;&emsp;划分数据集的大原则是:将无序的数据变得更加有序。  \n",
    "&emsp;&emsp;在划分数据集之前之后信息发生的变化称为信息增益,知道如何计算信息增益,我们就可以计算每个特征值划分数据集获得的信息增益,获得信息增益最高的特征就是最好的选择。  \n",
    "&emsp;&emsp;集合信息的度量方式称为香农熵或者简称为熵,熵定义为信息的期望值。  \n",
    "如果待分类的事务可能划分在多个分类之中,则符号x i 的信息定义为  \n",
    "$$l(x_i)=-log_2p(x_i)$$  \n",
    "其中$p(x_i)$是选择该分类的概率。  \n",
    "为了计算熵,我们需要计算所有类别所有可能值包含的信息期望值,通过下面的公式得到:  \n",
    "$$H=-\\sum_{i=1}^n p(x_i)log_2p(x_i)$$  \n",
    "其中n是分类的数目。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算给定数据集的香农熵:  \n",
    "&emsp;&emsp;首先,计算数据集中实例的总数。我们也可以在需要时再计算这个值,但是由于代码中多次用到这个值,为了提高代码效率,我们显式地声明一个变量保存实例总数。然后,创建一个数据字典,它的键值是最后一列的数值 。如果当前键值不存在,则扩展字典并将当前键值加入字典。每个键值都记录了当前类别出现的次数。最后,使用所有类标签的发生频率计算类别出现的概率。我们将用这个概率计算香农熵 ,统计所有类标签发生的次数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T02:23:20.855520Z",
     "start_time": "2020-12-19T02:23:20.848300Z"
    }
   },
   "outputs": [],
   "source": [
    "# 计算给定数据集的香农熵\n",
    "from math import log\n",
    "\n",
    "\n",
    "def calcShannonEnt(dataSet):\n",
    "    numEntries = len(dataSet)  # 计算数据集中实例的总数\n",
    "    labelCounts = {}           # 创建一个数据字典,它的键值是最后一列的数值\n",
    "    for featVec in dataSet:\n",
    "        currentLabel = featVec[-1]\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] = 0  # 如果当前键值不存在,则扩展字典并将当前键值加入字典\n",
    "        labelCounts[currentLabel] += 1  # 每个键值都记录了当前类别出现的次数\n",
    "    shannonEnt = 0\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key])/numEntries  # 使用所有类标签的发生频率计算类别出现的概率\n",
    "        shannonEnt -= prob*log(prob, 2)  # 计算香农熵\n",
    "    return shannonEnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$表3-1海洋生物数据$$  \n",
    "\n",
    "| |不浮出水面是否可以生存 |是否有脚蹼 |属于鱼类|  \n",
    "|:-:|:-:|:-:|:-:|  \n",
    "|1 |是 |是 |是 |  \n",
    "|2 |是 |是 |是 |  \n",
    "|3 |是 |否 |否 | \n",
    "|4 |否 |是 |否 | \n",
    "|5 |否 |是 |否 |   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建简单鱼鉴定数据集  \n",
    "利用createDataSet()函数得到表3-1所示的简单鱼鉴定数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T02:23:22.927307Z",
     "start_time": "2020-12-19T02:23:22.907691Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def creatDataSet():\n",
    "    dataSet = [[1, 1, 'yes'],\n",
    "               [1, 1, 'yes'],\n",
    "               [1, 0, 'no'],\n",
    "               [0, 1, 'no'],\n",
    "               [0, 1, 'no']]\n",
    "    labels = ['no surfacting', 'flippers']\n",
    "    return dataSet, labels\n",
    "myDat,labels = creatDataSet()\n",
    "myDat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T02:23:24.017793Z",
     "start_time": "2020-12-19T02:23:24.009896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcShannonEnt(myDat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T02:23:24.907293Z",
     "start_time": "2020-12-19T02:23:24.898753Z"
    }
   },
   "outputs": [],
   "source": [
    "dataSet = myDat\n",
    "numEntries = len(dataSet)  # 计算数据集中实例的总数\n",
    "labelCounts = {}           # 创建一个数据字典,它的键值是最后一列的数值\n",
    "for featVec in dataSet:\n",
    "    currentLabel = featVec[-1]\n",
    "    if currentLabel not in labelCounts.keys():\n",
    "        labelCounts[currentLabel] = 0  # 如果当前键值不存在,则扩展字典并将当前键值加入字典\n",
    "    labelCounts[currentLabel] += 1  # 每个键值都记录了当前类别出现的次数\n",
    "shannonEnt = 0\n",
    "for key in labelCounts:\n",
    "    prob = float(labelCounts[key])/numEntries  # 使用所有类标签的发生频率计算类别出现的概率\n",
    "    shannonEnt -= prob*log(prob, 2)  # 计算香农熵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T02:23:26.808559Z",
     "start_time": "2020-12-19T02:23:26.803302Z"
    }
   },
   "outputs": [],
   "source": [
    "def splitDataSet(dataSet, axis, value):\n",
    "    retDataSet = []  # 为了不修改原始数据集,创建一个新的列表对象\n",
    "    for featVec in dataSet:\n",
    "        if featVec[axis] == value:\n",
    "            reducedFeatVec = featVec[:axis]\n",
    "            reducedFeatVec.extend(featVec[axis+1:])\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T02:23:27.665563Z",
     "start_time": "2020-12-19T02:23:27.659042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, [4, 5, 6]]\n",
      "[1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "# append与extend区别\n",
    "# 假定存在两个列表，a，b\n",
    "a = [1,2,3]\n",
    "b = [4,5,6]\n",
    "a.append(b) #列表得到了第四个元素,而且第四个元素也是一个列表\n",
    "print(a)\n",
    "a = [1,2,3]\n",
    "a.extend(b) #得到一个包含a和b所有元素的列表\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T02:23:34.792101Z",
     "start_time": "2020-12-19T02:23:34.785432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n",
      "[[1, 'yes'], [1, 'yes'], [0, 'no']]\n",
      "[[1, 'no'], [1, 'no']]\n"
     ]
    }
   ],
   "source": [
    "#简单样本数据上测试函数 splitDataSet()\n",
    "print(myDat)\n",
    "print(splitDataSet(myDat,0,1))\n",
    "print(splitDataSet(myDat,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T02:54:31.453339Z",
     "start_time": "2020-12-19T02:54:31.442825Z"
    }
   },
   "outputs": [],
   "source": [
    "# 选择最好的数据集划分方式\n",
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    \"\"\"\n",
    "    在函数中调用的数据需要满足一定的要求:\n",
    "    1、数据必须是一种由列表元素组成的列表,而且所有的列表元素都要具有相同的数据长度;\n",
    "    2、数据的最后一列或者每个实例的最后一个元素是当前实例的类别标签。\n",
    "    \"\"\"\n",
    "    numFeatures = len(dataSet[0])-1  # 判定当前数据集包含多少特征属性\n",
    "    # 计算了整个数据集的原始香农熵,我们保存最初的无序度量值,用于与划分完之后的数据集计算的熵值进行比较。\n",
    "    baseEntroy = calcShannonEnt(dataSet)\n",
    "    bestInfGain = 0.0\n",
    "    bestFeature = -1\n",
    "    for i in range(numFeatures):  # 遍历数据集中的所有特征\n",
    "        # 使用列表推导(List Comprehension)来创建新的列表,将数据集中所有第i个特征值或者所有可能存在的值写入这个新list中\n",
    "        featList = [example[i] for example in dataSet]\n",
    "        uniqueVals = set(featList) #从列表中创建集合是Python语言得到列表中唯一元素值的最快方法。\n",
    "        newEntroy = 0.0\n",
    "        for value in uniqueVals: #遍历当前特征中的所有唯一属性值,对每个特征划分一次数据集\n",
    "            subDataSet = splitDataSet(dataSet,i,value)\n",
    "            prob = len(subDataSet)/float(len(dataSet))\n",
    "            newEntroy += prob * calcShannonEnt(subDataSet)\n",
    "        infoGain = baseEntroy - newEntroy\n",
    "        if(infoGain > bestInfGain):\n",
    "            bestInfGain = infoGain\n",
    "            bestFeature = i\n",
    "    return bestFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T02:55:07.794957Z",
     "start_time": "2020-12-19T02:55:07.785908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chooseBestFeatureToSplit(myDat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "150px",
    "left": "546px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
